{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "matplotlib.rcParams['figure.dpi'] = 144\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import base\n",
    "from sklearn import model_selection\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from pyspark import SparkConf, SparkContext\n",
    "from pyspark.sql import SQLContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Please note that I have chosen simplicity over more complicated approaches to solving this problem given the data size. This implementation needs modifications as the data size grows.\n",
    "After parallelizing the data through Spark, data I decided to use Pandas to process the data further. Therefore Apache Arrow was used to increase the performance with columnar data transfer. More info at http://arrow.apache.org/blog/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf().set(\"spark.sql.execution.arrow.enabled\", \"true\")\n",
    "sc= SparkContext(conf=conf)\n",
    "sqlContext = SQLContext(sc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do further analyses, I found Pandas the most comfortable option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Store_ID: int, Fiscal_Qtr: int, DateStringYYYYMMDD: int, Fiscal_dayofWk: int, Daypart: string, HourlyWeather: string, Hour: int, AvgHourlyTemp: double, SalesRevenue: double]"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sale_df = sqlContext.read.format('com.databricks.spark.csv').options(header='true', inferschema='true').load('file:///home/vagrant/datacourse/InterviewPractice/SalesbyHour.csv')\n",
    "sale_df.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To better understand the data, I charted the statistics of SalesRevenue data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>summary</th>\n",
       "      <td>count</td>\n",
       "      <td>mean</td>\n",
       "      <td>stddev</td>\n",
       "      <td>min</td>\n",
       "      <td>max</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Store_ID</th>\n",
       "      <td>125792</td>\n",
       "      <td>17.39299001526329</td>\n",
       "      <td>8.563273107108882</td>\n",
       "      <td>2</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fiscal_Qtr</th>\n",
       "      <td>125792</td>\n",
       "      <td>2.3677419867718137</td>\n",
       "      <td>1.0812984094686178</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DateStringYYYYMMDD</th>\n",
       "      <td>125792</td>\n",
       "      <td>2.0157441416353982E7</td>\n",
       "      <td>10356.963815778025</td>\n",
       "      <td>20131230</td>\n",
       "      <td>20170714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fiscal_dayofWk</th>\n",
       "      <td>125792</td>\n",
       "      <td>3.8709774866446196</td>\n",
       "      <td>1.9426759659612687</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Daypart</th>\n",
       "      <td>125792</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>Lunch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HourlyWeather</th>\n",
       "      <td>125792</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>clear-day</td>\n",
       "      <td>wind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hour</th>\n",
       "      <td>125792</td>\n",
       "      <td>13.685218455863648</td>\n",
       "      <td>4.026186626380106</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AvgHourlyTemp</th>\n",
       "      <td>125792</td>\n",
       "      <td>68.54871319320772</td>\n",
       "      <td>15.33677803893824</td>\n",
       "      <td>5.85</td>\n",
       "      <td>100.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SalesRevenue</th>\n",
       "      <td>125792</td>\n",
       "      <td>118.19987550877798</td>\n",
       "      <td>98.57650967976018</td>\n",
       "      <td>-822.62</td>\n",
       "      <td>3818.51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         0                     1                   2  \\\n",
       "summary              count                  mean              stddev   \n",
       "Store_ID            125792     17.39299001526329   8.563273107108882   \n",
       "Fiscal_Qtr          125792    2.3677419867718137  1.0812984094686178   \n",
       "DateStringYYYYMMDD  125792  2.0157441416353982E7  10356.963815778025   \n",
       "Fiscal_dayofWk      125792    3.8709774866446196  1.9426759659612687   \n",
       "Daypart             125792                  None                None   \n",
       "HourlyWeather       125792                  None                None   \n",
       "Hour                125792    13.685218455863648   4.026186626380106   \n",
       "AvgHourlyTemp       125792     68.54871319320772   15.33677803893824   \n",
       "SalesRevenue        125792    118.19987550877798   98.57650967976018   \n",
       "\n",
       "                            3         4  \n",
       "summary                   min       max  \n",
       "Store_ID                    2        38  \n",
       "Fiscal_Qtr                  1         4  \n",
       "DateStringYYYYMMDD   20131230  20170714  \n",
       "Fiscal_dayofWk              1         7  \n",
       "Daypart             Afternoon     Lunch  \n",
       "HourlyWeather       clear-day      wind  \n",
       "Hour                        0        23  \n",
       "AvgHourlyTemp            5.85    100.62  \n",
       "SalesRevenue          -822.62   3818.51  "
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sale_df.describe().toPandas().transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=sale_df.toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store_ID</th>\n",
       "      <th>Fiscal_Qtr</th>\n",
       "      <th>DateStringYYYYMMDD</th>\n",
       "      <th>Fiscal_dayofWk</th>\n",
       "      <th>Daypart</th>\n",
       "      <th>HourlyWeather</th>\n",
       "      <th>Hour</th>\n",
       "      <th>AvgHourlyTemp</th>\n",
       "      <th>SalesRevenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>20170714</td>\n",
       "      <td>5</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>rain</td>\n",
       "      <td>16</td>\n",
       "      <td>92.43</td>\n",
       "      <td>193.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>20170714</td>\n",
       "      <td>5</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>rain</td>\n",
       "      <td>14</td>\n",
       "      <td>89.56</td>\n",
       "      <td>323.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>20170714</td>\n",
       "      <td>5</td>\n",
       "      <td>Afternoon</td>\n",
       "      <td>rain</td>\n",
       "      <td>15</td>\n",
       "      <td>90.90</td>\n",
       "      <td>126.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>20170714</td>\n",
       "      <td>5</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>fog</td>\n",
       "      <td>8</td>\n",
       "      <td>77.35</td>\n",
       "      <td>154.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>20170714</td>\n",
       "      <td>5</td>\n",
       "      <td>Breakfast</td>\n",
       "      <td>partly-cloudy-day</td>\n",
       "      <td>9</td>\n",
       "      <td>79.06</td>\n",
       "      <td>89.60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store_ID  Fiscal_Qtr  DateStringYYYYMMDD  Fiscal_dayofWk    Daypart  \\\n",
       "0         2           3            20170714               5  Afternoon   \n",
       "1         2           3            20170714               5  Afternoon   \n",
       "2         2           3            20170714               5  Afternoon   \n",
       "3         2           3            20170714               5  Breakfast   \n",
       "4         2           3            20170714               5  Breakfast   \n",
       "\n",
       "       HourlyWeather  Hour  AvgHourlyTemp  SalesRevenue  \n",
       "0               rain    16          92.43        193.44  \n",
       "1               rain    14          89.56        323.84  \n",
       "2               rain    15          90.90        126.09  \n",
       "3                fog     8          77.35        154.54  \n",
       "4  partly-cloudy-day     9          79.06         89.60  "
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Charting the data types indicates that we have two categorical feature in our data set. Then it is necessary to convert them into numerical data for further analysis. However, before that to use the same data values in predicting new values, we need a dictionary to translate the categorical values to their new numerical values. This step was performed through CategoricalDict function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Store_ID                int64\n",
       "Fiscal_Qtr              int64\n",
       "DateStringYYYYMMDD      int64\n",
       "Fiscal_dayofWk          int64\n",
       "Daypart                object\n",
       "HourlyWeather          object\n",
       "Hour                    int64\n",
       "AvgHourlyTemp         float64\n",
       "SalesRevenue          float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 424,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining our Categorical translator before conversion.\n",
    "def CategoricalDict(X,col_names):\n",
    "    keys=[]\n",
    "    values=[]\n",
    "    for col in col_names:\n",
    "        values.append(X[col].astype('category').cat.codes.unique())\n",
    "        keys.append(X[col].unique())\n",
    "    return dict(zip([str(val) for sublist in keys for val in sublist], [val for sublist in values for val in sublist]))\n",
    "catDict=CategoricalDict(data,['HourlyWeather', 'Daypart'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Afternoon': 0,\n",
       " 'Breakfast': 1,\n",
       " 'Dinner': 2,\n",
       " 'Late Night': 3,\n",
       " 'Lunch': 4,\n",
       " 'clear-day': 0,\n",
       " 'clear-night': 1,\n",
       " 'cloudy': 2,\n",
       " 'fog': 3,\n",
       " 'partly-cloudy-day': 4,\n",
       " 'partly-cloudy-night': 5,\n",
       " 'rain': 6,\n",
       " 'snow': 7,\n",
       " 'wind': 8}"
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "catDict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then converted the categorical data to numerical values. (get_dummies technique could also be used but I preferred the following method for simplicity in visualization and to obtain the prediction for new variables easier.)\n",
    "Please note that this step could also be implemented at our Gridsearch pipeline but since our corr function needs our data in a numerical format, I performed this step separately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A function to convert cateorical values to numerical.\n",
    "def CategoricalTransformer(X,col_names):\n",
    "    for col in col_names:\n",
    "        X[col]= X[col].astype('category').cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "CategoricalTransformer(data,['HourlyWeather', 'Daypart'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let’s find the correlation between independent variables and the target variable.\n",
    "The result indicates that Sales Revenue has the strongest correlation with Daypart and Average Temperature among the others. Also, Fiscal Day of the week had a very low correlation with the Sales Revenue. (Then deleted). Please note that although HourlyWeather had the least correlation, I kept it in the dataset as we may need it to predict the 2017-07-15 total sale.\n",
    "\n",
    "### The top five predictors are:\n",
    "* Daypart\n",
    "* AvgHourlyTemp\n",
    "* Date\n",
    "* Hour\n",
    "* Fiscal_Qtr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store_ID</th>\n",
       "      <th>Fiscal_Qtr</th>\n",
       "      <th>DateStringYYYYMMDD</th>\n",
       "      <th>Fiscal_dayofWk</th>\n",
       "      <th>Daypart</th>\n",
       "      <th>HourlyWeather</th>\n",
       "      <th>Hour</th>\n",
       "      <th>AvgHourlyTemp</th>\n",
       "      <th>SalesRevenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Store_ID</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.034316</td>\n",
       "      <td>0.381757</td>\n",
       "      <td>0.001978</td>\n",
       "      <td>-0.016085</td>\n",
       "      <td>0.045069</td>\n",
       "      <td>-0.045565</td>\n",
       "      <td>-0.061617</td>\n",
       "      <td>0.031698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fiscal_Qtr</th>\n",
       "      <td>-0.034316</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.235690</td>\n",
       "      <td>-0.000698</td>\n",
       "      <td>-0.001142</td>\n",
       "      <td>-0.033210</td>\n",
       "      <td>-0.004150</td>\n",
       "      <td>0.252290</td>\n",
       "      <td>-0.047402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DateStringYYYYMMDD</th>\n",
       "      <td>0.381757</td>\n",
       "      <td>-0.235690</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.006231</td>\n",
       "      <td>-0.011564</td>\n",
       "      <td>0.116066</td>\n",
       "      <td>-0.030798</td>\n",
       "      <td>0.038984</td>\n",
       "      <td>0.173249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fiscal_dayofWk</th>\n",
       "      <td>0.001978</td>\n",
       "      <td>-0.000698</td>\n",
       "      <td>-0.006231</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.024729</td>\n",
       "      <td>-0.021084</td>\n",
       "      <td>0.058623</td>\n",
       "      <td>0.012291</td>\n",
       "      <td>0.020733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Daypart</th>\n",
       "      <td>-0.016085</td>\n",
       "      <td>-0.001142</td>\n",
       "      <td>-0.011564</td>\n",
       "      <td>0.024729</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.034912</td>\n",
       "      <td>0.025646</td>\n",
       "      <td>0.015433</td>\n",
       "      <td>0.269690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HourlyWeather</th>\n",
       "      <td>0.045069</td>\n",
       "      <td>-0.033210</td>\n",
       "      <td>0.116066</td>\n",
       "      <td>-0.021084</td>\n",
       "      <td>-0.034912</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.078927</td>\n",
       "      <td>0.112158</td>\n",
       "      <td>0.002888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hour</th>\n",
       "      <td>-0.045565</td>\n",
       "      <td>-0.004150</td>\n",
       "      <td>-0.030798</td>\n",
       "      <td>0.058623</td>\n",
       "      <td>0.025646</td>\n",
       "      <td>0.078927</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.255642</td>\n",
       "      <td>-0.076258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AvgHourlyTemp</th>\n",
       "      <td>-0.061617</td>\n",
       "      <td>0.252290</td>\n",
       "      <td>0.038984</td>\n",
       "      <td>0.012291</td>\n",
       "      <td>0.015433</td>\n",
       "      <td>0.112158</td>\n",
       "      <td>0.255642</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.221708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SalesRevenue</th>\n",
       "      <td>0.031698</td>\n",
       "      <td>-0.047402</td>\n",
       "      <td>0.173249</td>\n",
       "      <td>0.020733</td>\n",
       "      <td>0.269690</td>\n",
       "      <td>0.002888</td>\n",
       "      <td>-0.076258</td>\n",
       "      <td>0.221708</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Store_ID  Fiscal_Qtr  DateStringYYYYMMDD  Fiscal_dayofWk  \\\n",
       "Store_ID            1.000000   -0.034316            0.381757        0.001978   \n",
       "Fiscal_Qtr         -0.034316    1.000000           -0.235690       -0.000698   \n",
       "DateStringYYYYMMDD  0.381757   -0.235690            1.000000       -0.006231   \n",
       "Fiscal_dayofWk      0.001978   -0.000698           -0.006231        1.000000   \n",
       "Daypart            -0.016085   -0.001142           -0.011564        0.024729   \n",
       "HourlyWeather       0.045069   -0.033210            0.116066       -0.021084   \n",
       "Hour               -0.045565   -0.004150           -0.030798        0.058623   \n",
       "AvgHourlyTemp      -0.061617    0.252290            0.038984        0.012291   \n",
       "SalesRevenue        0.031698   -0.047402            0.173249        0.020733   \n",
       "\n",
       "                     Daypart  HourlyWeather      Hour  AvgHourlyTemp  \\\n",
       "Store_ID           -0.016085       0.045069 -0.045565      -0.061617   \n",
       "Fiscal_Qtr         -0.001142      -0.033210 -0.004150       0.252290   \n",
       "DateStringYYYYMMDD -0.011564       0.116066 -0.030798       0.038984   \n",
       "Fiscal_dayofWk      0.024729      -0.021084  0.058623       0.012291   \n",
       "Daypart             1.000000      -0.034912  0.025646       0.015433   \n",
       "HourlyWeather      -0.034912       1.000000  0.078927       0.112158   \n",
       "Hour                0.025646       0.078927  1.000000       0.255642   \n",
       "AvgHourlyTemp       0.015433       0.112158  0.255642       1.000000   \n",
       "SalesRevenue        0.269690       0.002888 -0.076258       0.221708   \n",
       "\n",
       "                    SalesRevenue  \n",
       "Store_ID                0.031698  \n",
       "Fiscal_Qtr             -0.047402  \n",
       "DateStringYYYYMMDD      0.173249  \n",
       "Fiscal_dayofWk          0.020733  \n",
       "Daypart                 0.269690  \n",
       "HourlyWeather           0.002888  \n",
       "Hour                   -0.076258  \n",
       "AvgHourlyTemp           0.221708  \n",
       "SalesRevenue            1.000000  "
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The labels were extracted and the Fiscal Quarter column was dropped. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data['SalesRevenue']\n",
    "X=data.drop(['SalesRevenue','Fiscal_dayofWk'] , axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided to plot the features to better understand the correlation of them with label variable. \n",
    "As plot illustrates, the hourly temperature is correlated with the revenue. \n",
    "It is also observed that revenue varies with other features. So I decided to keep these features while training the model. I also realized there are outliers in the data so scaling features using statistics that are robust to outliers will benefit our prediction. The RobustScaler performs this task at our preprocessing step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dict=dict(zip(list(X.columns), ['Store', 'Quarter', 'Date', 'Day Part','Weather','Time','Temperature'])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4eb47604b1e24b22a86515e01868c63b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>interactive</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in Jupyter Notebook or JupyterLab, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another notebook frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "interactive(children=(Dropdown(description=u'column', options=('Store_ID', 'Fiscal_Qtr', 'DateStringYYYYMMDD', 'Daypart', 'HourlyWeather', 'Hour', 'AvgHourlyTemp'), value='Store_ID'), Output()), _dom_classes=('widget-interact',))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ipywidgets import widgets\n",
    "\n",
    "def sales_plot(column):\n",
    "    plt.plot(X[column], y, '.')\n",
    "    plt.xlabel(data_dict[column])\n",
    "    plt.ylabel('Sales')\n",
    "    \n",
    "#dropdown_values = {\"{0}: {1}\".format(k, v):k for k, v in data_dict.items()}\n",
    "\n",
    "widgets.interact(sales_plot, column=list(X.columns));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process\n",
    "With a better sense of the data, we’re now able to go through and do some analysis on the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-processing\n",
    "In order to run our models on the data, I had to transform many of the variables. The following pre-processing steps were taken (Some were taken prior to Gridsearch pipeline:\n",
    "* Transforming categorical data into numerical values. (already performed above)\n",
    "* Extracting labels from the dataset and dropping features with the lowest correlation. (already performed above)\n",
    "* Removing outliers and scaling data using RobustScaler\n",
    "* Cross-validation using random permutation cross-validator which outperforms K-fold by shuffling the data. This helps us to minimize overfitting. Given the size of the data, splitting data into training and testing sets with a ration of 4 to 1 makes sense. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv=model_selection.ShuffleSplit(n_splits=5, test_size=0.2) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "I fit the data against multiple models with different parameters. The models I tested include:\n",
    "    * Ridge Regression\n",
    "    * Linear Regression\n",
    "    * Random Forest\n",
    "    * Residual Model\n",
    "    \n",
    "Pipeline for each of the above models are included at below, and the R^2 score of each is obtained to measure how well the model explains the X variables.\n",
    "\n",
    "It is worth mentioning that in residual estimator, I used a linear model to fit the linear part of the data, and used a non-linear model to fit the residual that the linear model can't fit. This estimator takes Ridge and RandomForest estimators. It uses the first to fit the raw data and the second to fit the residuals of the first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linear least squares with l2 regularization.\n",
    "Ridge_pipe = Pipeline([\n",
    "    ('scaler', RobustScaler()),\n",
    "    ('LinearModel', Ridge())\n",
    "    ])\n",
    "Ridge_param_grid={'LinearModel__alpha': np.linspace(0,15,16)} #Regularization strength, Gridsearch will find the best \n",
    "                                                                #parameter and will use it to train the model.\n",
    "\n",
    "Ridge_GridResult = model_selection.GridSearchCV(Ridge_pipe, \n",
    "                                          param_grid=Ridge_param_grid, \n",
    "                                          n_jobs=4, # run each hyperparameter in one of two parallel jobs\n",
    "                                          cv=cv, #Random permutation cross-validator\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordinary least squares Linear Regression.\n",
    "LR_pipe = Pipeline([\n",
    "    ('scaler', RobustScaler()),\n",
    "    ('LinearModel', LinearRegression())\n",
    "    ])\n",
    "LR_param_grid={'LinearModel__normalize': [True]} #Regularization strength\n",
    "\n",
    "LR_GridResult = model_selection.GridSearchCV(LR_pipe, \n",
    "                                          param_grid=LR_param_grid, \n",
    "                                          n_jobs=4, # run each hyperparameter in one of two parallel jobs\n",
    "                                          cv=cv, #Random permutation cross-validator\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 439,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A random forest regressor.\n",
    "RF_pipe = Pipeline([\n",
    "    ('scaler', RobustScaler()),\n",
    "    ('LinearModel', RandomForestRegressor())\n",
    "    ])\n",
    "RF_param_grid={'LinearModel__min_samples_leaf':[1]} #I hardcoded this parameter as it maximized the accuracy\n",
    "                                                    #the downside is it increases the coputation time.\n",
    "\n",
    "RF_GridResult = model_selection.GridSearchCV(RF_pipe, \n",
    "                                          param_grid=RF_param_grid, \n",
    "                                          n_jobs=4, # run each hyperparameter in one of two parallel jobs\n",
    "                                          cv=cv, #Random permutation cross-validator\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 440,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Residual Estimator\n",
    "non_linear=RandomForestRegressor()\n",
    "linear=Ridge()\n",
    "residEstim=ResidualEstimator(linear,non_linear)\n",
    "\n",
    "RM_pipe = Pipeline([\n",
    "    ('Model', ResidualEstimator(linear,non_linear))\n",
    "    ])\n",
    "RM_grid={'Model__nonlinear__min_samples_leaf':[1],\n",
    "            'Model__linear__alpha': np.linspace(0,1,15)\n",
    "           #\"LinearModel__max_depth\": range(1,11)\n",
    "           }\n",
    "\n",
    "RM_GridResult = model_selection.GridSearchCV(RM_pipe, \n",
    "                                          param_grid=RM_grid, \n",
    "                                          n_jobs=4, # run each hyperparameter in one of two parallel jobs\n",
    "                                          cv=cv, #Random permutation cross-validator\n",
    "                                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ridge_est=Ridge_GridResult.fit(X, y)\n",
    "LR_est=LR_GridResult.fit(X, y)\n",
    "RF_est=RF_GridResult.fit(X, y)\n",
    "RM_est=RM_GridResult.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scores indicate that our Residual Model slightly outperforms the RandomForest model compare to the other models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 of Ridge estimator:  0.173686674315\n",
      "R^2 of Linear Regression estimator:  0.173686691612\n",
      "R^2 of RandomForest estimator:  0.912727197521\n",
      "R^2 of Residual estimator:  0.911267380159\n"
     ]
    }
   ],
   "source": [
    "print \"R^2 of Ridge estimator: \", Ridge_est.score(X, y) \n",
    "print \"R^2 of Linear Regression estimator: \", LR_est.score(X, y)\n",
    "print \"R^2 of RandomForest estimator: \", RF_est.score(X, y)\n",
    "print \"R^2 of Residual estimator: \", RM_est.score(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our residual estimator was selected to predict the total sales revenue of all stores on 2017-07-15.\n",
    "At first, we need to create new values in a Panda friendly format and then feed them into our model to predict the total revenue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_prediction_data():\n",
    "    listofdata=[]\n",
    "    for store in range (1,15):\n",
    "        listofdata.append([store, 3, 20170715, catDict['Lunch'], catDict['clear-day'], 12, 86])\n",
    "    return (listofdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sales revenue of each store on 2017/07/15: [ 329.54354846  329.39760717  329.25166588  329.10572459  328.9597833\n",
      "  328.81384201  168.25234641  168.10640512  167.96046383  167.81452254\n",
      "  167.66858125  167.52263996  167.37669867  152.94025918]\n",
      "Total sales revenue of all 14 stores on 2017/07/15: 3302.71408839\n"
     ]
    }
   ],
   "source": [
    "#test_x=pd.Series((X.iloc[1]))\n",
    "print \"Sales revenue of each store on 2017/07/15:\", RM_est.predict(np.array(final_prediction_data()))\n",
    "print \"Total sales revenue of all 14 stores on 2017/07/15:\",sum(RM_est.predict(np.array(final_prediction_data())))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our model predicted the total sales revenue of all 14 stores on 2017/07/15: 3302.71408839"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
